{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEDNyyz_evXt",
        "outputId": "7c2955bb-3e94-405c-8cb5-9aa0cae5cbfb"
      },
      "outputs": [],
      "source": [
        "!pip install boto3\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WG0vtx4xeslV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from datetime import datetime, timezone\n",
        "import csv\n",
        "import json\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import boto3\n",
        "import shutil\n",
        "import random\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EV_0GP4nepQj"
      },
      "outputs": [],
      "source": [
        "CSV_PATH = '/content/image_segmentation_grey.csv'  # CSV with filtering criteria\n",
        "CSV_OUTPUT = '/content/image_boat_count.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RN5viZ_rffQh"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Automatic Boat Detection with Enhanced Filtering\n",
        "- Prevents double-counting with NMS tuning\n",
        "- Detects tiny boats (10-20px) and large boats\n",
        "- Filters: top 25% (mountains/sky), bottom 2%, right 5% corner\n",
        "- Processes only daytime images\n",
        "\"\"\"\n",
        "\n",
        "def load_daytime_images(csv_path):\n",
        "    \"\"\"Load CSV and return set of daytime image filenames\"\"\"\n",
        "    daytime_images = set()\n",
        "\n",
        "    with open(csv_path, 'r') as f:\n",
        "        reader = csv.reader(f)\n",
        "        for row in reader:\n",
        "            if len(row) >= 3:\n",
        "                filename = row[0].strip()\n",
        "                time_of_day = row[2].strip().lower()\n",
        "\n",
        "                if time_of_day == 'day':\n",
        "                    daytime_images.add(filename)\n",
        "\n",
        "    print(f\"Loaded {len(daytime_images)} daytime images from CSV\")\n",
        "    return daytime_images\n",
        "\n",
        "\n",
        "def is_in_exclusion_zone(box, width, height, exclude_top_percent=25, exclude_bottom_percent=20):\n",
        "    \"\"\"\n",
        "    Check if bounding box is in any exclusion zone\n",
        "\n",
        "    Args:\n",
        "        box: dict with 'xyxy' key containing [x1, y1, x2, y2]\n",
        "        width: image width\n",
        "        height: image height\n",
        "        exclude_top_percent: percentage of top to exclude\n",
        "        exclude_bottom_percent: percentage of bottom to exclude\n",
        "\n",
        "    Returns:\n",
        "        (is_excluded, reason) tuple\n",
        "    \"\"\"\n",
        "    x1, y1, x2, y2 = box['xyxy']\n",
        "\n",
        "    # Calculate boundaries\n",
        "    top_threshold = height * (exclude_top_percent / 100)\n",
        "    bottom_threshold = height * (1 - exclude_bottom_percent / 100)\n",
        "\n",
        "    # Check if center of box is in exclusion zone\n",
        "    y_center = (y1 + y2) / 2\n",
        "    x_center = (x1 + x2) / 2\n",
        "\n",
        "    if y_center < top_threshold:\n",
        "        return True, \"top_zone\"\n",
        "    if y2 > bottom_threshold:  # Check bottom edge instead of center\n",
        "        return True, \"bottom_zone\"\n",
        "    return False, None\n",
        "\n",
        "\n",
        "def calculate_iou(box1, box2):\n",
        "    \"\"\"Calculate Intersection over Union for two boxes\"\"\"\n",
        "    x1_1, y1_1, x2_1, y2_1 = box1['xyxy']\n",
        "    x1_2, y1_2, x2_2, y2_2 = box2['xyxy']\n",
        "\n",
        "    # Calculate intersection\n",
        "    x1_i = max(x1_1, x1_2)\n",
        "    y1_i = max(y1_1, y1_2)\n",
        "    x2_i = min(x2_1, x2_2)\n",
        "    y2_i = min(y2_1, y2_2)\n",
        "\n",
        "    if x2_i < x1_i or y2_i < y1_i:\n",
        "        return 0.0\n",
        "\n",
        "    intersection = (x2_i - x1_i) * (y2_i - y1_i)\n",
        "\n",
        "    # Calculate union\n",
        "    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
        "    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
        "    union = area1 + area2 - intersection\n",
        "\n",
        "    return intersection / union if union > 0 else 0.0\n",
        "\n",
        "\n",
        "def apply_custom_nms(boxes, iou_threshold=0.4):\n",
        "    \"\"\"\n",
        "    Apply custom Non-Maximum Suppression to prevent double-counting\n",
        "    Keeps highest confidence box when overlap exceeds threshold\n",
        "\n",
        "    Args:\n",
        "        boxes: list of box dicts with 'xyxy' and 'conf' keys\n",
        "        iou_threshold: IoU threshold for considering boxes as duplicates\n",
        "\n",
        "    Returns:\n",
        "        tuple: (kept_boxes, suppressed_boxes)\n",
        "    \"\"\"\n",
        "    if len(boxes) == 0:\n",
        "        return [], []\n",
        "\n",
        "    # Sort by confidence (highest first)\n",
        "    boxes_sorted = sorted(boxes, key=lambda x: x['conf'], reverse=True)\n",
        "\n",
        "    keep = []\n",
        "    suppressed = []\n",
        "\n",
        "    while len(boxes_sorted) > 0:\n",
        "        # Take highest confidence box\n",
        "        current = boxes_sorted.pop(0)\n",
        "        keep.append(current)\n",
        "\n",
        "        # Remove boxes that overlap significantly\n",
        "        remaining = []\n",
        "        for box in boxes_sorted:\n",
        "            iou = calculate_iou(current, box)\n",
        "            if iou < iou_threshold:\n",
        "                remaining.append(box)\n",
        "            else:\n",
        "                suppressed.append(box)\n",
        "\n",
        "        boxes_sorted = remaining\n",
        "\n",
        "    return keep, suppressed\n",
        "\n",
        "\n",
        "def detect_boats_yolo(model,\n",
        "    image_folder,\n",
        "    output_folder,\n",
        "    csv_path=None,\n",
        "    export_format='yolo',\n",
        "    exclude_top_percent=25,\n",
        "    exclude_bottom_percent=20,\n",
        "    confidence_threshold=0.05,  # Very low for tiny boats (increase if too many false positives)\n",
        "    iou_threshold=0.5,  # NMS threshold for duplicate detection\n",
        "    imgsz=1920  # Larger image size critical for 10-20px boats\n",
        "):\n",
        "    \"\"\"\n",
        "    Detect boats using YOLO with enhanced filtering and NMS\n",
        "\n",
        "    Args:\n",
        "        image_folder: Input folder with images\n",
        "        output_folder: Output folder for annotations\n",
        "        csv_path: Path to CSV with daytime/nighttime labels (optional)\n",
        "        export_format: 'yolo', 'coco', or 'voc'\n",
        "        exclude_top_percent: Percentage of top to exclude (mountains/sky)\n",
        "        exclude_bottom_percent: Percentage of bottom to exclude\n",
        "        exclude_right_percent: Percentage of right edge to exclude\n",
        "        confidence_threshold: Minimum confidence (0.05 aggressive, 0.15 conservative)\n",
        "        iou_threshold: IoU threshold for NMS (0.3=aggressive, 0.6=conservative)\n",
        "        model_name: YOLO model to use (yolo11x.pt recommended for tiny boats)\n",
        "        imgsz: Image size for inference (larger = better tiny boat detection)\n",
        "    \"\"\"\n",
        "\n",
        "    # Load daytime filter if CSV provided\n",
        "    daytime_images = None\n",
        "    if csv_path:\n",
        "        daytime_images = load_daytime_images(csv_path)\n",
        "\n",
        "    # Create output directories\n",
        "    Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
        "    labels_folder = Path(output_folder) / 'labels'\n",
        "    images_folder = Path(output_folder) / 'images'\n",
        "    labels_folder.mkdir(exist_ok=True)\n",
        "    images_folder.mkdir(exist_ok=True)\n",
        "\n",
        "    annotations = []\n",
        "    image_id = 0\n",
        "    total_detections = 0\n",
        "    skipped_nighttime = 0\n",
        "\n",
        "    # Tracking statistics\n",
        "    stats = {\n",
        "        'filtered_low_conf': 0,\n",
        "        'filtered_top_zone': 0,\n",
        "        'filtered_bottom_zone': 0,\n",
        "        'filtered_nms': 0,\n",
        "        'tiny_boats': 0,  # <= 20px max dimension\n",
        "        'small_boats': 0,  # 21-50px\n",
        "        'medium_boats': 0,  # 51-100px\n",
        "        'large_boats': 0   # > 100px\n",
        "    }\n",
        "\n",
        "    # Process all images\n",
        "    image_files = list(Path(image_folder).glob('*.jpg')) + \\\n",
        "                  list(Path(image_folder).glob('*.png')) + \\\n",
        "                  list(Path(image_folder).glob('*.jpeg'))\n",
        "\n",
        "    print(f\"\\nProcessing {len(image_files)} image...\")\n",
        "\n",
        "    for img_path in image_files:\n",
        "        # Skip nighttime images if CSV filter is active\n",
        "        if daytime_images and img_path.name not in daytime_images:\n",
        "            skipped_nighttime += 1\n",
        "            continue\n",
        "\n",
        "        # Read image\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None:\n",
        "            print(f\"Warning: Could not read {img_path.name}\")\n",
        "            continue\n",
        "\n",
        "        height, width = img.shape[:2]\n",
        "\n",
        "        # Run inference with settings optimized for tiny boats\n",
        "        # Very low conf threshold and larger image size\n",
        "        results = model(\n",
        "            img,\n",
        "            conf=confidence_threshold,\n",
        "            iou=0.9,  # YOLO's built-in NMS - very high to keep almost all detections\n",
        "            imgsz=imgsz,\n",
        "            max_det=300,  # Allow more detections per image (default is 300)\n",
        "            agnostic_nms=False,  # Class-specific NMS\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        # Extract boat detections (class 8 in COCO)\n",
        "        raw_boxes = []\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                class_id = int(box.cls[0])\n",
        "                if class_id == 8:  # boat class\n",
        "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "                    confidence = float(box.conf[0])\n",
        "\n",
        "                    raw_boxes.append({\n",
        "                        'xyxy': [float(x1), float(y1), float(x2), float(y2)],\n",
        "                        'conf': confidence,\n",
        "                        'class': class_id\n",
        "                    })\n",
        "\n",
        "        # Apply region-based filtering\n",
        "        filtered_boxes = []\n",
        "        for box in raw_boxes:\n",
        "            excluded, reason = is_in_exclusion_zone(\n",
        "                box, width, height,\n",
        "                exclude_top_percent,\n",
        "                exclude_bottom_percent\n",
        "            )\n",
        "\n",
        "            if excluded:\n",
        "                stats[f'filtered_{reason}'] += 1\n",
        "            else:\n",
        "                filtered_boxes.append(box)\n",
        "\n",
        "        # Apply custom NMS to prevent double-counting\n",
        "        final_boxes, suppressed_boxes = apply_custom_nms(filtered_boxes, iou_threshold)\n",
        "        stats['filtered_nms'] += len(suppressed_boxes)\n",
        "\n",
        "        # Categorize boats by size\n",
        "        for box in final_boxes:\n",
        "            x1, y1, x2, y2 = box['xyxy']\n",
        "            box_width = x2 - x1\n",
        "            box_height = y2 - y1\n",
        "            max_dim = max(box_width, box_height)\n",
        "\n",
        "            if max_dim <= 20:\n",
        "                stats['tiny_boats'] += 1\n",
        "                box['size_category'] = 'tiny'\n",
        "            elif max_dim <= 50:\n",
        "                stats['small_boats'] += 1\n",
        "                box['size_category'] = 'small'\n",
        "            elif max_dim <= 100:\n",
        "                stats['medium_boats'] += 1\n",
        "                box['size_category'] = 'medium'\n",
        "            else:\n",
        "                stats['large_boats'] += 1\n",
        "                box['size_category'] = 'large'\n",
        "\n",
        "        total_detections += len(final_boxes)\n",
        "\n",
        "        # Print status\n",
        "        status = f\"{img_path.name}: {len(final_boxes)} boats\"\n",
        "        if len(final_boxes) > 0:\n",
        "            size_counts = {}\n",
        "            for box in final_boxes:\n",
        "                cat = box['size_category']\n",
        "                size_counts[cat] = size_counts.get(cat, 0) + 1\n",
        "            size_str = \", \".join([f\"{count} {cat}\" for cat, count in sorted(size_counts.items())])\n",
        "            status += f\" ({size_str})\"\n",
        "\n",
        "        filters = []\n",
        "        if len(suppressed_boxes) > 0:\n",
        "            filters.append(f\"{len(suppressed_boxes)} duplicates\")\n",
        "        if filters:\n",
        "            status += f\" [filtered: {', '.join(filters)}]\"\n",
        "\n",
        "        # Export annotations\n",
        "        if export_format == 'yolo':\n",
        "            export_yolo_format(img_path, final_boxes, width, height, labels_folder)\n",
        "        elif export_format == 'coco':\n",
        "            export_coco_format(img_path, final_boxes, width, height, image_id, annotations)\n",
        "        elif export_format == 'voc':\n",
        "            export_voc_format(img_path, final_boxes, width, height, labels_folder)\n",
        "\n",
        "        # Save annotated image with color-coded boxes by size\n",
        "        annotated_img = img.copy()\n",
        "\n",
        "        # Draw exclusion zones first (as transparent overlays)\n",
        "        overlay = annotated_img.copy()\n",
        "\n",
        "        # Top zone (mountains/sky) - red\n",
        "        top_threshold = int(height * (exclude_top_percent / 100))\n",
        "        cv2.rectangle(overlay, (0, 0), (width, top_threshold), (0, 0, 255), -1)\n",
        "\n",
        "        # Bottom zone - orange\n",
        "        bottom_threshold = int(height * (1 - exclude_bottom_percent / 100))\n",
        "        cv2.rectangle(overlay, (0, bottom_threshold), (width, height), (0, 165, 255), -1)\n",
        "\n",
        "        # Blend overlay with original\n",
        "        cv2.addWeighted(overlay, 0.2, annotated_img, 0.8, 0, annotated_img)\n",
        "\n",
        "        # Draw boundary lines\n",
        "        cv2.line(annotated_img, (0, top_threshold), (width, top_threshold), (0, 0, 255), 2)\n",
        "        cv2.line(annotated_img, (0, bottom_threshold), (width, bottom_threshold), (0, 165, 255), 2)\n",
        "\n",
        "        # Draw boat bounding boxes with color by size\n",
        "        for box in final_boxes:\n",
        "            x1, y1, x2, y2 = [int(v) for v in box['xyxy']]\n",
        "\n",
        "            # Color code by size: tiny=green, small=cyan, medium=blue, large=magenta\n",
        "            color_map = {\n",
        "                'tiny': (0, 255, 0),      # Green\n",
        "                'small': (255, 255, 0),    # Cyan\n",
        "                'medium': (255, 128, 0),   # Blue\n",
        "                'large': (255, 0, 255)     # Magenta\n",
        "            }\n",
        "            color = color_map.get(box['size_category'], (0, 255, 0))\n",
        "\n",
        "            cv2.rectangle(annotated_img, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "            # Add label with confidence and size\n",
        "            box_w, box_h = x2 - x1, y2 - y1\n",
        "            label = f\"{box['size_category']} {box['conf']:.2f} ({int(max(box_w, box_h))}px)\"\n",
        "\n",
        "            # Background for text\n",
        "            (text_w, text_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.4, 1)\n",
        "            cv2.rectangle(annotated_img, (x1, y1 - text_h - 4), (x1 + text_w, y1), color, -1)\n",
        "            cv2.putText(annotated_img, label, (x1, y1 - 2),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)\n",
        "\n",
        "        # Add legend\n",
        "        legend_y = 30\n",
        "        cv2.putText(annotated_img, f\"Boats: {len(final_boxes)}\", (10, legend_y),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "\n",
        "        cv2.imwrite(str(images_folder / img_path.name), annotated_img)\n",
        "        image_id += 1\n",
        "\n",
        "    # Save COCO JSON if needed\n",
        "    if export_format == 'coco':\n",
        "        save_coco_json(annotations, output_folder)\n",
        "\n",
        "    return total_detections\n",
        "\n",
        "def export_yolo_format(img_path, boxes, width, height, labels_folder):\n",
        "    \"\"\"YOLO format: class x_center y_center width height (normalized)\"\"\"\n",
        "    label_path = labels_folder / f\"{img_path.stem}.txt\"\n",
        "\n",
        "    with open(label_path, 'w') as f:\n",
        "        for box in boxes:\n",
        "            x1, y1, x2, y2 = box['xyxy']\n",
        "\n",
        "            # Convert to YOLO format (normalized center coords + size)\n",
        "            x_center = ((x1 + x2) / 2) / width\n",
        "            y_center = ((y1 + y2) / 2) / height\n",
        "            box_width = (x2 - x1) / width\n",
        "            box_height = (y2 - y1) / height\n",
        "\n",
        "            f.write(f\"0 {x_center:.6f} {y_center:.6f} {box_width:.6f} {box_height:.6f}\\n\")\n",
        "\n",
        "\n",
        "def export_coco_format(img_path, boxes, width, height, image_id, annotations):\n",
        "    \"\"\"COCO format: JSON with images and annotations arrays\"\"\"\n",
        "    for idx, box in enumerate(boxes):\n",
        "        x1, y1, x2, y2 = box['xyxy']\n",
        "\n",
        "        annotation = {\n",
        "            'id': image_id * 1000 + idx,\n",
        "            'image_id': image_id,\n",
        "            'category_id': 1,\n",
        "            'bbox': [float(x1), float(y1), float(x2 - x1), float(y2 - y1)],\n",
        "            'area': float((x2 - x1) * (y2 - y1)),\n",
        "            'iscrowd': 0,\n",
        "            'score': box['conf']\n",
        "        }\n",
        "        annotations.append(annotation)\n",
        "\n",
        "\n",
        "def save_coco_json(annotations, output_folder):\n",
        "    \"\"\"Save COCO format JSON file\"\"\"\n",
        "    coco_data = {\n",
        "        'images': [],\n",
        "        'annotations': annotations,\n",
        "        'categories': [{'id': 1, 'name': 'boat'}]\n",
        "    }\n",
        "\n",
        "    json_path = Path(output_folder) / 'annotations.json'\n",
        "    with open(json_path, 'w') as f:\n",
        "        json.dump(coco_data, f, indent=2)\n",
        "\n",
        "\n",
        "def export_voc_format(img_path, boxes, width, height, labels_folder):\n",
        "    \"\"\"Pascal VOC format: XML file per image\"\"\"\n",
        "    import xml.etree.ElementTree as ET\n",
        "\n",
        "    root = ET.Element('annotation')\n",
        "    ET.SubElement(root, 'filename').text = img_path.name\n",
        "\n",
        "    size = ET.SubElement(root, 'size')\n",
        "    ET.SubElement(size, 'width').text = str(width)\n",
        "    ET.SubElement(size, 'height').text = str(height)\n",
        "    ET.SubElement(size, 'depth').text = '3'\n",
        "\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = box['xyxy']\n",
        "\n",
        "        obj = ET.SubElement(root, 'object')\n",
        "        ET.SubElement(obj, 'name').text = 'boat'\n",
        "\n",
        "        bndbox = ET.SubElement(obj, 'bndbox')\n",
        "        ET.SubElement(bndbox, 'xmin').text = str(int(x1))\n",
        "        ET.SubElement(bndbox, 'ymin').text = str(int(y1))\n",
        "        ET.SubElement(bndbox, 'xmax').text = str(int(x2))\n",
        "        ET.SubElement(bndbox, 'ymax').text = str(int(y2))\n",
        "\n",
        "    tree = ET.ElementTree(root)\n",
        "    xml_path = labels_folder / f\"{img_path.stem}.xml\"\n",
        "    tree.write(xml_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xNhd-pjh-dF"
      },
      "source": [
        "# Get Filtered Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoJcBdBXh9ps",
        "outputId": "5767e99d-c426-45cd-ade9-032a685add79"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_and_remove_day_image(csv_path, segment_column='segment', image_column=None):\n",
        "    \"\"\"\n",
        "    Get one day image, remove it from CSV, and return the image name\n",
        "\n",
        "    Args:\n",
        "        csv_path: Path to local CSV file\n",
        "        segment_column: Column name containing 'day'/'night' (default: 'segment')\n",
        "        image_column: Column name containing image filenames (auto-detect if None)\n",
        "\n",
        "    Returns:\n",
        "        str: Image filename, or None if no day images found\n",
        "    \"\"\"\n",
        "    # Load CSV\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    print(f\"Loaded CSV with {len(df)} rows\")\n",
        "\n",
        "    # Filter for day images\n",
        "    day_images = df[df[segment_column] == 'day']\n",
        "\n",
        "    if len(day_images) == 0:\n",
        "        print(\"No day images found in CSV\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Found {len(day_images)} day images\")\n",
        "\n",
        "    # Get the first day image row\n",
        "    day_row = day_images.iloc[0]\n",
        "\n",
        "    # Auto-detect image column if not specified\n",
        "    if image_column is None:\n",
        "        for col in ['image', 'filename', 'file', 'image_name', 'image_path']:\n",
        "            if col in df.columns:\n",
        "                image_column = col\n",
        "                break\n",
        "        if image_column is None:\n",
        "            image_column = df.columns[0]  # Use first column as fallback\n",
        "\n",
        "    image_name = day_row[image_column]\n",
        "\n",
        "    # Remove this row from dataframe\n",
        "    df = df.drop(day_row.name)\n",
        "\n",
        "    # Save modified CSV back to file\n",
        "    df.to_csv(csv_path, index=False)\n",
        "\n",
        "    print(f\"Removed image '{image_name}' from CSV\")\n",
        "    print(f\"CSV now has {len(df)} rows ({len(df[df[segment_column] == 'day'])} day images remaining)\")\n",
        "\n",
        "    return image_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z8bC-O5iX0Z"
      },
      "source": [
        "## Parse Timestamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCJqCARDiXlT"
      },
      "outputs": [],
      "source": [
        "def parse_timestamp_from_filename(filename):\n",
        "    \"\"\"\n",
        "    Extract and parse timestamp from filename.\n",
        "\n",
        "    Args:\n",
        "        filename: Image filename\n",
        "        image_type: 'ccss' for raw CCSS images, 'gt' for ground truth images\n",
        "\n",
        "    Examples:\n",
        "        CCSS: AXISQ6074EPTZACCC8EACA584_20230901T210530.000Z.jpg\n",
        "    \"\"\"\n",
        "    TIMESTAMP_PATTERN = r'_(\\d{8}T\\d{6}\\.\\d{3}Z)\\.'\n",
        "    match = re.search(TIMESTAMP_PATTERN, filename)\n",
        "    if not match:\n",
        "        return None\n",
        "    timestamp_str = match.group(1)\n",
        "    dt = datetime.strptime(timestamp_str, '%Y%m%dT%H%M%S.%fZ')\n",
        "    return dt.strftime('%Y-%m-%d %H:%M:%S')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqtD2Fd8gEVL"
      },
      "source": [
        "## Create CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVVwHZmZc_Hm",
        "outputId": "1f0b6408-3858-4663-b17e-d0c47482bcf4"
      },
      "outputs": [],
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import multiprocessing as mp\n",
        "import os\n",
        "import shutil\n",
        "import boto3\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "import threading\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "CSV_PATH = '/content/image_segmentation_grey.csv'  # CSV with filtering criteria\n",
        "CSV_OUTPUT = '/content/image_boat_count.csv'\n",
        "\n",
        "def get_all_day_images(csv_path, filename_col=None, segment_col='segment', segment_val='day', limit=None):\n",
        "    \"\"\"\n",
        "    Extract all day image filenames from CSV\n",
        "\n",
        "    Args:\n",
        "        csv_path: Path to CSV file\n",
        "        filename_col: Name of column containing filenames (None = auto-detect)\n",
        "        segment_col: Name of column containing time segment (None = use all)\n",
        "        segment_val: Value indicating day segment (default: 'day')\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path)\n",
        "\n",
        "        print(f\"\\nðŸ“‹ CSV Info: {len(df)} rows, Columns: {list(df.columns)}\")\n",
        "\n",
        "        # Auto-detect filename column if not specified\n",
        "        if filename_col is None:\n",
        "            possible_names = ['filename', 'file_name', 'image', 'image_name',\n",
        "                            'image_path', 'path', 'name', 'file']\n",
        "            filename_col = next((col for col in df.columns\n",
        "                               if col.lower() in possible_names), df.columns[0])\n",
        "\n",
        "        print(f\"âœ“ Using filename column: '{filename_col}'\")\n",
        "\n",
        "        # Filter by segment if specified\n",
        "        if segment_col and segment_col in df.columns:\n",
        "            day_images = df[df[segment_col] == segment_val][filename_col].tolist()\n",
        "            print(f\"âœ“ Filtered for '{segment_val}' in '{segment_col}'\")\n",
        "        else:\n",
        "            day_images = df[filename_col].tolist()\n",
        "            print(f\"â„¹ï¸  No segment filter applied\")\n",
        "\n",
        "        if limit is not None and limit > 0:\n",
        "            original_count = len(day_images)\n",
        "            day_images = day_images[:limit]\n",
        "            print(f\"ðŸ”’ Limited from {original_count} to {len(day_images)} images\")\n",
        "\n",
        "        print(f\"âœ“ Processing {len(day_images)} images\")\n",
        "\n",
        "        # Show sample filenames\n",
        "        if day_images:\n",
        "            print(f\"\\nðŸ“ Sample filenames:\")\n",
        "            for fname in day_images[:3]:\n",
        "                print(f\"   - {fname}\")\n",
        "\n",
        "        return day_images\n",
        "\n",
        "        print(f\"âœ“ Found {len(day_images)} images\")\n",
        "        print(f\"   Sample: {day_images[0] if day_images else 'N/A'}\")\n",
        "\n",
        "        return day_images\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Error: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def process_single_image(file_name, s3, bucket_name, folder_prefix,\n",
        "                        model, base_image_folder, output_folder, segment):\n",
        "    \"\"\"\n",
        "    Process one image - download, detect boats, cleanup\n",
        "    Thread-safe with isolated folder per thread\n",
        "    \"\"\"\n",
        "    # Create thread-specific folder to avoid conflicts\n",
        "    thread_id = threading.current_thread().ident\n",
        "    thread_image_folder = os.path.join(base_image_folder, f\"thread_{thread_id}\")\n",
        "    os.makedirs(thread_image_folder, exist_ok=True)\n",
        "\n",
        "    local_file_path = os.path.join(thread_image_folder, os.path.basename(file_name))\n",
        "    s3_key = f\"{folder_prefix}{file_name}\"\n",
        "\n",
        "    try:\n",
        "        # Check if file exists in S3\n",
        "        s3.head_object(Bucket=bucket_name, Key=s3_key)\n",
        "\n",
        "        # Download image\n",
        "        s3.download_file(bucket_name, s3_key, local_file_path)\n",
        "\n",
        "        # Detect boats - process only this thread's folder\n",
        "        boat_count = detect_boats_yolo(\n",
        "            model,\n",
        "            image_folder=thread_image_folder,  # Thread-specific folder\n",
        "            output_folder=output_folder,\n",
        "            csv_path=None,  # Process all images in folder (just this one)\n",
        "            export_format='yolo',\n",
        "            exclude_top_percent=25,\n",
        "            exclude_bottom_percent=25,\n",
        "            confidence_threshold=0.10,\n",
        "            iou_threshold=0.3,\n",
        "            imgsz=1920\n",
        "        )\n",
        "\n",
        "        # Parse timestamp from filename\n",
        "        timestamp = parse_timestamp_from_filename(file_name)\n",
        "\n",
        "        result = {\n",
        "            'filename': file_name,\n",
        "            'timestamp': timestamp,\n",
        "            'segment': segment,\n",
        "            'boat_count': boat_count\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâœ— Failed {file_name}: {e}\")\n",
        "        return None\n",
        "\n",
        "    finally:\n",
        "        # Always cleanup thread folder\n",
        "        if os.path.exists(thread_image_folder):\n",
        "            try:\n",
        "                shutil.rmtree(thread_image_folder)\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not cleanup {thread_image_folder}: {e}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "\n",
        "    # ============== CONFIGURATION ==============\n",
        "    # Define your paths here\n",
        "    CSV_PATH = \"image_segmentation_grey.csv\"  # UPDATE THIS\n",
        "    CSV_OUTPUT = \"boat_detection_results.csv\"  # UPDATE THIS\n",
        "\n",
        "    original_path = Path(CSV_PATH)\n",
        "    CSV_PATH_DUP = str(original_path.parent / f\"{original_path.stem}_dup{original_path.suffix}\")\n",
        "\n",
        "    # S3 Configuration\n",
        "    #bucket_name =\n",
        "    #folder_prefix =\n",
        "    IMAGE_FOLDER = './CCSS_images/'\n",
        "    OUTPUT_FOLDER = \"./annotated_boats\"\n",
        "\n",
        "    # Processing Configuration\n",
        "    segment = 'day'\n",
        "    max_workers = 8  # Tune this: 4-8 for balanced, 10+ for network-heavy\n",
        "\n",
        "    # ============== SETUP ==============\n",
        "    print(\"=\"*60)\n",
        "    print(\"ðŸš€ Starting Parallel Boat Detection Pipeline\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Copy CSV for backup\n",
        "    shutil.copy2(CSV_PATH, CSV_PATH_DUP)\n",
        "    print(f\"âœ“ Created backup CSV: {CSV_PATH_DUP}\")\n",
        "\n",
        "    # Initialize S3 client\n",
        "    s3 = boto3.client(\n",
        "        #'s3',\n",
        "        #aws_access_key_id=,\n",
        "        #aws_secret_access_key=,\n",
        "        #endpoint_url=\n",
        "    )\n",
        "    print(\"âœ“ S3 client initialized\")\n",
        "\n",
        "    # Load YOLO model (once, shared across threads)\n",
        "    print(\"â³ Loading YOLO model...\")\n",
        "    model = YOLO('yolo11m.pt')\n",
        "    print(\"âœ“ YOLO model loaded\")\n",
        "\n",
        "    # Create folders\n",
        "    os.makedirs(IMAGE_FOLDER, exist_ok=True)\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "    print(f\"âœ“ Folders created: {IMAGE_FOLDER}, {OUTPUT_FOLDER}\")\n",
        "\n",
        "    # ============== GET FILE LIST ==============\n",
        "    file_list = get_all_day_images(CSV_PATH_DUP)\n",
        "\n",
        "    if not file_list:\n",
        "        print(\"âŒ No files to process!\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nðŸ“‹ Processing {len(file_list)} images with {max_workers} parallel workers\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # ============== PARALLEL PROCESSING ==============\n",
        "    results = []\n",
        "    failed_files = []\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        # Submit all tasks\n",
        "        futures = {\n",
        "            executor.submit(\n",
        "                process_single_image,\n",
        "                fname,\n",
        "                s3,\n",
        "                bucket_name,\n",
        "                folder_prefix,\n",
        "                model,\n",
        "                IMAGE_FOLDER,\n",
        "                OUTPUT_FOLDER,\n",
        "                segment\n",
        "            ): fname\n",
        "            for fname in file_list\n",
        "        }\n",
        "\n",
        "        # Process results with progress bar\n",
        "        for future in tqdm(as_completed(futures), total=len(file_list),\n",
        "                          desc=\"Processing images\", unit=\"img\"):\n",
        "            result = future.result()\n",
        "            if result:\n",
        "                results.append(result)\n",
        "            else:\n",
        "                # Track failed files\n",
        "                failed_files.append(futures[future])\n",
        "\n",
        "    # ============== SAVE RESULTS ==============\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ðŸ’¾ Saving results...\")\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(CSV_OUTPUT, index=False)\n",
        "\n",
        "    # ============== SUMMARY ==============\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"âœ… PROCESSING COMPLETE!\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"ðŸ“„ Output CSV: {CSV_OUTPUT}\")\n",
        "    print(f\"ðŸ“Š Total images processed: {len(file_list)}\")\n",
        "    print(f\"âœ“ Successful: {len(results)}\")\n",
        "    print(f\"âœ— Failed: {len(failed_files)}\")\n",
        "\n",
        "    if failed_files:\n",
        "        print(f\"\\nâš ï¸  Failed files:\")\n",
        "        for f in failed_files[:10]:  # Show first 10\n",
        "            print(f\"   - {f}\")\n",
        "        if len(failed_files) > 10:\n",
        "            print(f\"   ... and {len(failed_files) - 10} more\")\n",
        "\n",
        "    print(f\"\\nðŸ“ˆ Results preview:\")\n",
        "    print(df.head(10))\n",
        "\n",
        "    print(f\"\\nðŸ“Š Boat count statistics:\")\n",
        "    print(df['boat_count'].describe())\n",
        "\n",
        "    # Cleanup backup CSV\n",
        "    try:\n",
        "        os.remove(CSV_PATH_DUP)\n",
        "        print(f\"\\nâœ“ Cleaned up backup CSV\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ðŸŽ‰ All done!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "tROrqHU2MSWk",
        "outputId": "d16e48a6-1e6b-4dcb-8db4-cfffa89c4625"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Display single image with boat detection boxes\n",
        "\"\"\"\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def read_yolo_labels(label_path, img_width, img_height):\n",
        "    \"\"\"\n",
        "    Read YOLO format labels and convert to pixel coordinates\n",
        "    Format: class x_center y_center width height (all normalized 0-1)\n",
        "    \"\"\"\n",
        "    boxes = []\n",
        "\n",
        "    if not label_path.exists():\n",
        "        return boxes\n",
        "\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 5:\n",
        "                class_id = int(parts[0])\n",
        "                x_center = float(parts[1]) * img_width\n",
        "                y_center = float(parts[2]) * img_height\n",
        "                width = float(parts[3]) * img_width\n",
        "                height = float(parts[4]) * img_height\n",
        "\n",
        "                # Convert to corner coordinates\n",
        "                x1 = int(x_center - width / 2)\n",
        "                y1 = int(y_center - height / 2)\n",
        "                x2 = int(x_center + width / 2)\n",
        "                y2 = int(y_center + height / 2)\n",
        "\n",
        "                boxes.append((x1, y1, x2, y2, class_id))\n",
        "\n",
        "    return boxes\n",
        "\n",
        "\n",
        "def draw_boxes_on_image(img, boxes, color=(0, 255, 0), thickness=2):\n",
        "    \"\"\"\n",
        "    Draw bounding boxes on image\n",
        "    \"\"\"\n",
        "    img_copy = img.copy()\n",
        "\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2, class_id = box\n",
        "        cv2.rectangle(img_copy, (x1, y1), (x2, y2), color, thickness)\n",
        "\n",
        "        # Add label\n",
        "        label = f\"boat\"\n",
        "        cv2.putText(img_copy, label, (x1, y1 - 10),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    return img_copy\n",
        "\n",
        "\n",
        "def display_single_image(base_folder, image_filename):\n",
        "    \"\"\"\n",
        "    Display a single image with boat detection boxes\n",
        "\n",
        "    Args:\n",
        "        base_folder: Path to folder containing 'images' and 'labels' subfolders\n",
        "        image_filename: Name of the image file (e.g., 'image001.jpg')\n",
        "    \"\"\"\n",
        "    base_path = Path(base_folder)\n",
        "    images_path = base_path / 'images'\n",
        "    labels_path = base_path / 'labels'\n",
        "\n",
        "    # Construct full image path\n",
        "    img_path = images_path / image_filename\n",
        "\n",
        "    if not img_path.exists():\n",
        "        print(f\"Image not found: {img_path}\")\n",
        "        return\n",
        "\n",
        "    # Read image\n",
        "    img = cv2.imread(str(img_path))\n",
        "    if img is None:\n",
        "        print(f\"Failed to read image: {img_path}\")\n",
        "        return\n",
        "\n",
        "    height, width = img.shape[:2]\n",
        "\n",
        "    # Read corresponding label file\n",
        "    label_path = labels_path / f\"{img_path.stem}.txt\"\n",
        "    boxes = read_yolo_labels(label_path, width, height)\n",
        "\n",
        "    # Draw boxes if present\n",
        "    if boxes:\n",
        "        img_with_boxes = draw_boxes_on_image(img, boxes, color=(0, 255, 0))\n",
        "        img_rgb = cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB)\n",
        "        title_text = f'{image_filename}\\n{len(boxes)} boat(s) detected'\n",
        "        print(f\"Displaying image with {len(boxes)} boat detection(s)\")\n",
        "    else:\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        title_text = f'{image_filename}\\nNo boats detected'\n",
        "        print(f\"Displaying image with no boat detections\")\n",
        "\n",
        "    # Display\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    ax.imshow(img_rgb)\n",
        "    ax.axis('off')\n",
        "    ax.set_title(title_text, fontsize=12, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Example: display specific image\n",
        "    image_filename = \"AXISQ6074EPTZACCC8EACA584_20230901T000001.000Z.jpg\"\n",
        "\n",
        "    display_single_image('/content/annotated_boats',image_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "r6oumGI3sHeA",
        "outputId": "3e349f5f-ecf5-4516-d4e2-317d9240a7b9"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Display daytime images split by boat detection status\n",
        "\"\"\"\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "def load_daytime_images(csv_path):\n",
        "    \"\"\"\n",
        "    Load CSV and return set of daytime image filenames\n",
        "\n",
        "    CSV format expected:\n",
        "    filename,timestamp,time_of_day\n",
        "    AXISQ6074EPTZACCC8EACA584_20230901T164001.000Z.jpg,2023-09-01 16:40:01.000 UTC,day\n",
        "    \"\"\"\n",
        "    daytime_images = set()\n",
        "\n",
        "    with open(csv_path, 'r') as f:\n",
        "        reader = csv.reader(f)\n",
        "        for row in reader:\n",
        "            if len(row) >= 3:\n",
        "                filename = row[0].strip()\n",
        "                time_of_day = row[2].strip().lower()\n",
        "\n",
        "                if time_of_day == 'day':\n",
        "                    daytime_images.add(filename)\n",
        "\n",
        "    print(f\"Loaded {len(daytime_images)} daytime images from CSV\")\n",
        "    return daytime_images\n",
        "\n",
        "\n",
        "def read_yolo_labels(label_path, img_width, img_height):\n",
        "    \"\"\"\n",
        "    Read YOLO format labels and convert to pixel coordinates\n",
        "    Format: class x_center y_center width height (all normalized 0-1)\n",
        "    \"\"\"\n",
        "    boxes = []\n",
        "\n",
        "    if not label_path.exists():\n",
        "        return boxes\n",
        "\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 5:\n",
        "                class_id = int(parts[0])\n",
        "                x_center = float(parts[1]) * img_width\n",
        "                y_center = float(parts[2]) * img_height\n",
        "                width = float(parts[3]) * img_width\n",
        "                height = float(parts[4]) * img_height\n",
        "\n",
        "                # Convert to corner coordinates\n",
        "                x1 = int(x_center - width / 2)\n",
        "                y1 = int(y_center - height / 2)\n",
        "                x2 = int(x_center + width / 2)\n",
        "                y2 = int(y_center + height / 2)\n",
        "\n",
        "                boxes.append((x1, y1, x2, y2, class_id))\n",
        "\n",
        "    return boxes\n",
        "\n",
        "\n",
        "def draw_boxes_on_image(img, boxes, color=(0, 255, 0), thickness=2):\n",
        "    \"\"\"\n",
        "    Draw bounding boxes on image\n",
        "    \"\"\"\n",
        "    img_copy = img.copy()\n",
        "\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2, class_id = box\n",
        "        cv2.rectangle(img_copy, (x1, y1), (x2, y2), color, thickness)\n",
        "\n",
        "        # Add label\n",
        "        label = f\"boat\"\n",
        "        cv2.putText(img_copy, label, (x1, y1 - 10),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    return img_copy\n",
        "\n",
        "\n",
        "def display_daytime_split(base_folder, num_with_boats=20, num_without_boats=20):\n",
        "    \"\"\"\n",
        "    Display daytime images split into two categories:\n",
        "    1. Images WITH boat detections\n",
        "    2. Images WITHOUT boat detections\n",
        "\n",
        "    Args:\n",
        "        base_folder: Path to folder containing 'images' and 'labels' subfolders\n",
        "        csv_path: Path to CSV with daytime/nighttime labels\n",
        "        num_with_boats: Number of images with boats to display\n",
        "        num_without_boats: Number of images without boats to display\n",
        "    \"\"\"\n",
        "    base_path = Path(base_folder)\n",
        "    images_path = base_path / 'images'\n",
        "    labels_path = base_path / 'labels'\n",
        "\n",
        "    if not images_path.exists():\n",
        "        print(f\"Images folder not found: {images_path}\")\n",
        "        return\n",
        "\n",
        "    if not labels_path.exists():\n",
        "        print(f\"Labels folder not found: {labels_path}\")\n",
        "        return\n",
        "\n",
        "    # Get all image files\n",
        "    all_image_files = (list(images_path.glob('*.jpg')) +\n",
        "                      list(images_path.glob('*.png')) +\n",
        "                      list(images_path.glob('*.jpeg')))\n",
        "\n",
        "    # Filter for daytime only\n",
        "    image_files = all_image_files\n",
        "\n",
        "    print(f\"Found {len(image_files)} daytime images (filtered from {len(all_image_files)} total)\")\n",
        "\n",
        "    # Categorize images\n",
        "    images_with_boats = []\n",
        "    images_without_boats = []\n",
        "\n",
        "    for img_path in sorted(image_files):\n",
        "        label_path = labels_path / f\"{img_path.stem}.txt\"\n",
        "\n",
        "        # Check if label file exists and has content\n",
        "        has_boats = False\n",
        "        if label_path.exists():\n",
        "            with open(label_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "                has_boats = len(lines) > 0\n",
        "\n",
        "        if has_boats:\n",
        "            images_with_boats.append(img_path)\n",
        "        else:\n",
        "            images_without_boats.append(img_path)\n",
        "\n",
        "    print(f\"\\nDaytime images with boats: {len(images_with_boats)}\")\n",
        "    print(f\"Daytime images without boats: {len(images_without_boats)}\")\n",
        "\n",
        "    # Limit to requested numbers\n",
        "    images_with_boats = images_with_boats[:num_with_boats]\n",
        "    images_without_boats = images_without_boats[:num_without_boats]\n",
        "\n",
        "    # Display images with boats\n",
        "    if images_with_boats:\n",
        "        print(f\"\\n=== DISPLAYING {len(images_with_boats)} IMAGES WITH BOATS ===\")\n",
        "        display_image_grid(images_with_boats, labels_path,\n",
        "                          title=\"DAYTIME IMAGES WITH BOATS\",\n",
        "                          color=(0, 255, 0))\n",
        "\n",
        "    # Display images without boats\n",
        "    if images_without_boats:\n",
        "        print(f\"\\n=== DISPLAYING {len(images_without_boats)} IMAGES WITHOUT BOATS ===\")\n",
        "        display_image_grid(images_without_boats, labels_path,\n",
        "                          title=\"DAYTIME IMAGES WITHOUT BOATS\",\n",
        "                          color=(255, 0, 0))\n",
        "\n",
        "\n",
        "def display_image_grid(image_files, labels_path, title=\"Images\", color=(0, 255, 0)):\n",
        "    \"\"\"\n",
        "    Display a grid of images with their bounding boxes\n",
        "    \"\"\"\n",
        "    n = len(image_files)\n",
        "    cols = 5  # 5 images per row\n",
        "    rows = (n + cols - 1) // cols\n",
        "\n",
        "    # Create figure\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(20, 4 * rows))\n",
        "    fig.suptitle(title, fontsize=16, fontweight='bold', y=0.995)\n",
        "\n",
        "    # Handle single row case\n",
        "    if rows == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    # Flatten axes for easy iteration\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    # Display each image\n",
        "    for idx, img_path in enumerate(image_files):\n",
        "        # Read image\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        height, width = img.shape[:2]\n",
        "\n",
        "        # Read corresponding label file\n",
        "        label_path = labels_path / f\"{img_path.stem}.txt\"\n",
        "        boxes = read_yolo_labels(label_path, width, height)\n",
        "\n",
        "        # Draw boxes if present\n",
        "        if boxes:\n",
        "            img_with_boxes = draw_boxes_on_image(img, boxes, color=color)\n",
        "            img_rgb = cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB)\n",
        "            title_text = f'{img_path.name}\\n{len(boxes)} boats'\n",
        "        else:\n",
        "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            title_text = f'{img_path.name}\\nNo boats'\n",
        "\n",
        "        # Display\n",
        "        axes[idx].imshow(img_rgb)\n",
        "        axes[idx].axis('off')\n",
        "        axes[idx].set_title(title_text, fontsize=8)\n",
        "\n",
        "    # Hide unused subplots\n",
        "    for idx in range(len(image_files), len(axes)):\n",
        "        axes[idx].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def get_detection_summary(base_folder, csv_path):\n",
        "    \"\"\"\n",
        "    Print summary statistics of daytime boat detections\n",
        "    \"\"\"\n",
        "    base_path = Path(base_folder)\n",
        "    images_path = base_path / 'images'\n",
        "    labels_path = base_path / 'labels'\n",
        "\n",
        "    # Load daytime filter\n",
        "    daytime_images = load_daytime_images(csv_path)\n",
        "\n",
        "    # Get all image files\n",
        "    all_image_files = (list(images_path.glob('*.jpg')) +\n",
        "                      list(images_path.glob('*.png')) +\n",
        "                      list(images_path.glob('*.jpeg')))\n",
        "\n",
        "    # Filter for daytime\n",
        "    image_files = [f for f in all_image_files if f.name in daytime_images]\n",
        "\n",
        "    total_daytime = len(image_files)\n",
        "    with_boats = 0\n",
        "    without_boats = 0\n",
        "    total_boat_count = 0\n",
        "\n",
        "    for img_path in image_files:\n",
        "        label_path = labels_path / f\"{img_path.stem}.txt\"\n",
        "\n",
        "        if label_path.exists():\n",
        "            with open(label_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "                boat_count = len(lines)\n",
        "                total_boat_count += boat_count\n",
        "\n",
        "                if boat_count > 0:\n",
        "                    with_boats += 1\n",
        "                else:\n",
        "                    without_boats += 1\n",
        "        else:\n",
        "            without_boats += 1\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"DAYTIME BOAT DETECTION SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Total daytime images: {total_daytime}\")\n",
        "    #print(f\"Images with boats: {with_boats} ({with_boats/total_daytime*100:.1f}%)\")\n",
        "    #print(f\"Images without boats: {without_boats} ({without_boats/total_daytime*100:.1f}%)\")\n",
        "    print(f\"Total boat detections: {total_boat_count}\")\n",
        "    if with_boats > 0:\n",
        "        print(f\"Average boats per image (when present): {total_boat_count/with_boats:.2f}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# USAGE EXAMPLES\n",
        "# ============================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Get summary statistics\n",
        "    get_detection_summary(\n",
        "        base_folder=\"annotated_boats\",\n",
        "        csv_path=\"image_segmentation_grey.csv\"\n",
        "    )\n",
        "\n",
        "    # Display split view: images with boats vs without boats\n",
        "    display_daytime_split(\n",
        "        base_folder=\"annotated_boats\",\n",
        "        num_with_boats=100,      # Number of images WITH boats to show\n",
        "        num_without_boats=100    # Number of images WITHOUT boats to show\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9mnvAN3IW9h_",
        "outputId": "37f3646f-4d7c-48cc-be34-c62f584af1cf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib import rcParams\n",
        "\n",
        "# Set professional style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "rcParams['font.family'] = 'sans-serif'\n",
        "rcParams['font.sans-serif'] = ['Arial', 'Helvetica', 'DejaVu Sans']\n",
        "rcParams['font.size'] = 11\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('combined_boat_data.csv')  # Replace with your actual filename\n",
        "\n",
        "# Extract the timestamp part (after the underscore, before the file extension)\n",
        "df['timestamp'] = df['filename'].str.extract(r'_(\\d{8}T\\d{6})')[0]\n",
        "\n",
        "# Convert to datetime\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y%m%dT%H%M%S')\n",
        "\n",
        "# Extract date components\n",
        "df['month'] = df['timestamp'].dt.month\n",
        "df['year'] = df['timestamp'].dt.year\n",
        "df['week'] = df['timestamp'].dt.isocalendar().week\n",
        "df['day_of_week'] = df['timestamp'].dt.day_name()\n",
        "df['day_num'] = df['timestamp'].dt.dayofweek\n",
        "\n",
        "# Filter for June and December\n",
        "june_data = df[df['month'] == 6].copy()\n",
        "dec_data = df[df['month'] == 12].copy()\n",
        "\n",
        "# Day configuration\n",
        "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "day_short = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "\n",
        "# Modern, vibrant color palette\n",
        "day_colors = {\n",
        "    'Monday': '#3498db',      # Bright blue\n",
        "    'Tuesday': '#e74c3c',     # Vibrant red\n",
        "    'Wednesday': '#2ecc71',   # Fresh green\n",
        "    'Thursday': '#f39c12',    # Golden orange\n",
        "    'Friday': '#9b59b6',      # Purple\n",
        "    'Saturday': '#1abc9c',    # Turquoise\n",
        "    'Sunday': '#e67e22'       # Deep orange\n",
        "}\n",
        "\n",
        "def create_professional_histogram(data, month_name, color_scheme='blue'):\n",
        "    \"\"\"Create a professional-looking grouped histogram\"\"\"\n",
        "    if len(data) == 0:\n",
        "        print(f\"No data for {month_name}\")\n",
        "        return\n",
        "\n",
        "    # Prepare data\n",
        "    data['year_week'] = data['year'].astype(str) + '-W' + data['week'].astype(str).str.zfill(2)\n",
        "    weeks = sorted(data[['year', 'week', 'year_week']].drop_duplicates().values.tolist(),\n",
        "                   key=lambda x: (x[0], x[1]))\n",
        "\n",
        "    week_labels = []\n",
        "    data_matrix = []\n",
        "\n",
        "    for year, week, year_week in weeks:\n",
        "        week_labels.append(year_week)\n",
        "        week_data = data[(data['year'] == year) & (data['week'] == week)]\n",
        "\n",
        "        day_counts = []\n",
        "        for day in day_order:\n",
        "            day_df = week_data[week_data['day_of_week'] == day]\n",
        "            count = day_df['boat_count'].sum() if len(day_df) > 0 else 0\n",
        "            day_counts.append(count)\n",
        "\n",
        "        data_matrix.append(day_counts)\n",
        "\n",
        "    data_matrix = np.array(data_matrix)\n",
        "    n_weeks = len(week_labels)\n",
        "\n",
        "    # Create figure with better proportions\n",
        "    fig = plt.figure(figsize=(max(18, n_weeks * 1.5), 9))\n",
        "    ax = fig.add_subplot(111)\n",
        "\n",
        "    # Set background color\n",
        "    fig.patch.set_facecolor('#f8f9fa')\n",
        "    ax.set_facecolor('#ffffff')\n",
        "\n",
        "    # Bar configuration\n",
        "    bar_width = 0.115\n",
        "    x = np.arange(n_weeks)\n",
        "\n",
        "    # Plot bars for each day\n",
        "    bars_list = []\n",
        "    for day_idx, day in enumerate(day_order):\n",
        "        offset = (day_idx - 3) * bar_width\n",
        "        bars = ax.bar(x + offset,\n",
        "                     data_matrix[:, day_idx],\n",
        "                     bar_width,\n",
        "                     label=day_short[day_idx],\n",
        "                     color=day_colors[day],\n",
        "                     edgecolor='white',\n",
        "                     linewidth=1.5,\n",
        "                     alpha=0.85,\n",
        "                     zorder=3)\n",
        "        bars_list.append(bars)\n",
        "\n",
        "        # Add value labels with better styling\n",
        "        for i, bar in enumerate(bars):\n",
        "            height = bar.get_height()\n",
        "            if height > 0:\n",
        "                ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                       f'{int(height)}',\n",
        "                       ha='center', va='bottom',\n",
        "                       fontsize=9, fontweight='600',\n",
        "                       color='#2c3e50')\n",
        "\n",
        "    # Styling\n",
        "    ax.set_xlabel('Week', fontsize=14, fontweight='bold', color='#2c3e50', labelpad=10)\n",
        "    ax.set_ylabel('Boat Count', fontsize=14, fontweight='bold', color='#2c3e50', labelpad=10)\n",
        "\n",
        "    # Title with better styling\n",
        "    title_color = '#16a085' if month_name == 'June' else '#d35400'\n",
        "    ax.set_title(f'{month_name} Weekly Boat Traffic by Day',\n",
        "                fontsize=20, fontweight='bold', color=title_color, pad=25)\n",
        "\n",
        "    # X-axis configuration\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(week_labels, rotation=45, ha='right', fontsize=11, color='#34495e')\n",
        "\n",
        "    # Y-axis configuration\n",
        "    ax.tick_params(axis='y', labelsize=11, colors='#34495e')\n",
        "\n",
        "    # Legend styling\n",
        "    legend = ax.legend(title='Day of Week',\n",
        "                      loc='upper left',\n",
        "                      fontsize=11,\n",
        "                      title_fontsize=12,\n",
        "                      frameon=True,\n",
        "                      fancybox=True,\n",
        "                      shadow=True,\n",
        "                      ncol=7,\n",
        "                      bbox_to_anchor=(0, 1.02, 1, 0.1),\n",
        "                      mode='expand',\n",
        "                      borderaxespad=0)\n",
        "    legend.get_frame().set_facecolor('#ffffff')\n",
        "    legend.get_frame().set_alpha(0.95)\n",
        "    legend.get_frame().set_edgecolor('#bdc3c7')\n",
        "\n",
        "    # Grid styling\n",
        "    ax.grid(axis='y', alpha=0.3, linestyle='-', linewidth=0.8, color='#bdc3c7', zorder=0)\n",
        "    ax.set_axisbelow(True)\n",
        "\n",
        "    # Spines styling\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_color('#bdc3c7')\n",
        "    ax.spines['bottom'].set_color('#bdc3c7')\n",
        "    ax.spines['left'].set_linewidth(1.5)\n",
        "    ax.spines['bottom'].set_linewidth(1.5)\n",
        "\n",
        "    # Y-axis limits\n",
        "    y_max = data_matrix.max()\n",
        "    ax.set_ylim(0, y_max * 1.2)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print clean statistics\n",
        "    print(f\"\\n{'â”€' * 90}\")\n",
        "    print(f\"  {month_name.upper()} WEEKLY ANALYSIS\")\n",
        "    print(f\"{'â”€' * 90}\\n\")\n",
        "\n",
        "    for idx, (year, week, year_week) in enumerate(weeks):\n",
        "        week_total = int(data_matrix[idx].sum())\n",
        "        peak_day_idx = data_matrix[idx].argmax()\n",
        "        peak_day = day_order[peak_day_idx]\n",
        "        peak_count = int(data_matrix[idx, peak_day_idx])\n",
        "\n",
        "        print(f\"  ðŸ“… {year_week}\")\n",
        "        print(f\"     Total: {week_total} boats  |  Peak: {peak_day} ({peak_count} boats)\")\n",
        "\n",
        "        # Compact daily breakdown\n",
        "        daily = \" | \".join([f\"{day_short[i]}: {int(data_matrix[idx, i])}\"\n",
        "                           for i in range(7) if data_matrix[idx, i] > 0])\n",
        "        print(f\"     {daily}\\n\")\n",
        "\n",
        "# Generate histograms\n",
        "print(\"\\n\" + \"â•\" * 90)\n",
        "print(\"  ðŸŒŠ BOAT TRAFFIC ANALYSIS - VISUAL REPORTS\")\n",
        "print(\"â•\" * 90)\n",
        "\n",
        "create_professional_histogram(june_data, 'June', 'blue')\n",
        "create_professional_histogram(dec_data, 'December', 'orange')\n",
        "\n",
        "print(\"â•\" * 90)\n",
        "print(\"  âœ… Analysis Complete!\")\n",
        "print(\"â•\" * 90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "thw0pOx7U1fK",
        "outputId": "25e51b0c-42d6-437f-9157-3a4368cb23ee"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from datetime import datetime\n",
        "from matplotlib import rcParams\n",
        "\n",
        "# Set professional style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "rcParams['font.family'] = 'sans-serif'\n",
        "rcParams['font.sans-serif'] = ['Arial', 'Helvetica', 'DejaVu Sans']\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('combined_boat_data.csv')  # Your combined CSV\n",
        "\n",
        "print(f\"Total rows loaded: {len(df)}\")\n",
        "print(f\"Columns: {df.columns.tolist()}\\n\")\n",
        "\n",
        "# Extract timestamp from filename\n",
        "# Assuming filename format like: 20231215_143022.jpg or 2023-12-15_14-30-22.jpg\n",
        "def extract_timestamp(filename):\n",
        "    \"\"\"Extract timestamp from various filename formats\"\"\"\n",
        "    try:\n",
        "        # Try format: YYYYMMDD_HHMMSS\n",
        "        match = re.search(r'(\\d{8})_(\\d{6})', str(filename))\n",
        "        if match:\n",
        "            date_str = match.group(1) + match.group(2)\n",
        "            return pd.to_datetime(date_str, format='%Y%m%d%H%M%S')\n",
        "\n",
        "        # Try format: YYYY-MM-DD_HH-MM-SS\n",
        "        match = re.search(r'(\\d{4})-(\\d{2})-(\\d{2})_(\\d{2})-(\\d{2})-(\\d{2})', str(filename))\n",
        "        if match:\n",
        "            date_str = ''.join(match.groups())\n",
        "            return pd.to_datetime(date_str, format='%Y%m%d%H%M%S')\n",
        "\n",
        "        # Try format: YYYYMMDD\n",
        "        match = re.search(r'(\\d{8})', str(filename))\n",
        "        if match:\n",
        "            return pd.to_datetime(match.group(1), format='%Y%m%d')\n",
        "\n",
        "        return None\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Apply timestamp extraction\n",
        "df['timestamp'] = df['filename'].apply(extract_timestamp)\n",
        "\n",
        "# Check how many timestamps were successfully extracted\n",
        "valid_timestamps = df['timestamp'].notna().sum()\n",
        "print(f\"âœ“ Successfully extracted {valid_timestamps} timestamps from filenames\")\n",
        "\n",
        "if valid_timestamps == 0:\n",
        "    print(\"\\nâš ï¸  Could not extract timestamps from filenames.\")\n",
        "    print(\"Sample filenames:\")\n",
        "    print(df['filename'].head(10))\n",
        "    print(\"\\nPlease check the filename format!\")\n",
        "    exit()\n",
        "\n",
        "# Remove rows without valid timestamps\n",
        "df = df[df['timestamp'].notna()].copy()\n",
        "\n",
        "# Extract year-month for grouping\n",
        "df['year_month'] = df['timestamp'].dt.to_period('M')\n",
        "\n",
        "# Group by year-month and sum boat counts\n",
        "monthly_counts = df.groupby('year_month')['boat_count'].sum().reset_index()\n",
        "\n",
        "# Sort chronologically\n",
        "monthly_counts = monthly_counts.sort_values('year_month')\n",
        "\n",
        "# Convert period to string for plotting\n",
        "monthly_counts['year_month_str'] = monthly_counts['year_month'].astype(str)\n",
        "\n",
        "# Create the professional histogram\n",
        "fig = plt.figure(figsize=(16, 8))\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "# Set background colors\n",
        "fig.patch.set_facecolor('#f8f9fa')\n",
        "ax.set_facecolor('#ffffff')\n",
        "\n",
        "# Create bars with gradient effect\n",
        "bars = ax.bar(range(len(monthly_counts)),\n",
        "              monthly_counts['boat_count'],\n",
        "              color='#3498db',\n",
        "              edgecolor='white',\n",
        "              linewidth=2,\n",
        "              alpha=0.85,\n",
        "              zorder=3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, (bar, count) in enumerate(zip(bars, monthly_counts['boat_count'])):\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "           f'{int(count)}',\n",
        "           ha='center', va='bottom',\n",
        "           fontsize=10, fontweight='bold',\n",
        "           color='#2c3e50')\n",
        "\n",
        "# Styling\n",
        "ax.set_xticks(range(len(monthly_counts)))\n",
        "ax.set_xticklabels(monthly_counts['year_month_str'],\n",
        "                   rotation=45, ha='right', fontsize=11, color='#34495e')\n",
        "ax.set_xlabel('Month', fontsize=14, fontweight='bold', color='#2c3e50', labelpad=12)\n",
        "ax.set_ylabel('Total Boat Count', fontsize=14, fontweight='bold', color='#2c3e50', labelpad=12)\n",
        "ax.set_title('Monthly Boat Count Analysis',\n",
        "            fontsize=20, fontweight='bold', color='#16a085', pad=25)\n",
        "\n",
        "# Grid styling\n",
        "ax.grid(axis='y', alpha=0.3, linestyle='-', linewidth=0.8, color='#bdc3c7', zorder=0)\n",
        "ax.set_axisbelow(True)\n",
        "\n",
        "# Spines styling\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['left'].set_color('#bdc3c7')\n",
        "ax.spines['bottom'].set_color('#bdc3c7')\n",
        "ax.spines['left'].set_linewidth(1.5)\n",
        "ax.spines['bottom'].set_linewidth(1.5)\n",
        "\n",
        "# Y-axis configuration\n",
        "ax.tick_params(axis='y', labelsize=11, colors='#34495e')\n",
        "y_max = monthly_counts['boat_count'].max()\n",
        "ax.set_ylim(0, y_max * 1.15)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print detailed statistics\n",
        "print(\"\\n\" + \"â•\" * 80)\n",
        "print(\"  ðŸ“Š MONTHLY BOAT COUNT STATISTICS\")\n",
        "print(\"â•\" * 80)\n",
        "print(f\"\\n  Total months analyzed: {len(monthly_counts)}\")\n",
        "print(f\"  Total boats detected: {monthly_counts['boat_count'].sum()}\")\n",
        "print(f\"  Average boats per month: {monthly_counts['boat_count'].mean():.2f}\")\n",
        "print(f\"  Median boats per month: {monthly_counts['boat_count'].median():.2f}\")\n",
        "print(f\"  Peak month: {monthly_counts.loc[monthly_counts['boat_count'].idxmax(), 'year_month_str']} \"\n",
        "      f\"with {monthly_counts['boat_count'].max()} boats\")\n",
        "print(f\"  Lowest month: {monthly_counts.loc[monthly_counts['boat_count'].idxmin(), 'year_month_str']} \"\n",
        "      f\"with {monthly_counts['boat_count'].min()} boats\")\n",
        "\n",
        "# Show top 5 busiest months\n",
        "print(f\"\\n  ðŸ”¥ Top 5 Busiest Months:\")\n",
        "print(\"  \" + \"â”€\" * 50)\n",
        "top_5 = monthly_counts.nlargest(5, 'boat_count')\n",
        "for idx, row in top_5.iterrows():\n",
        "    print(f\"     {row['year_month_str']}: {int(row['boat_count'])} boats\")\n",
        "\n",
        "# Show monthly breakdown\n",
        "print(f\"\\n  ðŸ“… Monthly Breakdown:\")\n",
        "print(\"  \" + \"â”€\" * 50)\n",
        "for idx, row in monthly_counts.iterrows():\n",
        "    bar_length = int((row['boat_count'] / y_max) * 40)\n",
        "    bar = \"â–ˆ\" * bar_length\n",
        "    print(f\"     {row['year_month_str']}: {bar} {int(row['boat_count'])}\")\n",
        "\n",
        "print(\"\\n\" + \"â•\" * 80)\n",
        "print(\"  âœ… Analysis Complete!\")\n",
        "print(\"â•\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGcG1BnbeEgH",
        "outputId": "3c047fb0-c97e-46ed-c8c9-1fc84ea20b29"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the two CSV files\n",
        "csv1 = pd.read_csv('boat_detection_results.csv')  # Has 'filename' column\n",
        "csv2 = pd.read_csv('boat_detections_parallel.csv')  # Has 'image' column\n",
        "\n",
        "# Display original columns\n",
        "print(\"CSV 1 columns:\", csv1.columns.tolist())\n",
        "print(\"CSV 2 columns:\", csv2.columns.tolist())\n",
        "print(f\"\\nCSV 1 rows: {len(csv1)}\")\n",
        "print(f\"CSV 2 rows: {len(csv2)}\")\n",
        "\n",
        "# Standardize column names for both CSVs\n",
        "# CSV1: keep only filename and boat_count columns\n",
        "if 'filename' in csv1.columns:\n",
        "    csv1_clean = csv1[['filename', 'boat_count']].copy()\n",
        "else:\n",
        "    print(\"ERROR: 'filename' column not found in CSV 1\")\n",
        "    exit()\n",
        "\n",
        "# CSV2: rename 'image' to 'filename' and keep only filename and boat_count\n",
        "if 'image' in csv2.columns:\n",
        "    csv2_clean = csv2[['image', 'boat_count']].copy()\n",
        "    csv2_clean = csv2_clean.rename(columns={'image': 'filename'})\n",
        "    print(\"\\nâœ“ Renamed 'image' to 'filename' in CSV 2\")\n",
        "elif 'filename' in csv2.columns:\n",
        "    csv2_clean = csv2[['filename', 'boat_count']].copy()\n",
        "else:\n",
        "    print(\"ERROR: Neither 'image' nor 'filename' column found in CSV 2\")\n",
        "    exit()\n",
        "\n",
        "print(\"âœ“ Keeping only 'filename' and 'boat_count' columns\")\n",
        "\n",
        "# Combine the two dataframes\n",
        "combined_df = pd.concat([csv1_clean, csv2_clean], ignore_index=True)\n",
        "\n",
        "print(f\"\\nâœ“ Combined CSV rows: {len(combined_df)}\")\n",
        "print(f\"âœ“ Combined CSV columns: {combined_df.columns.tolist()}\")\n",
        "\n",
        "# Remove any duplicate rows (optional)\n",
        "combined_df = combined_df.drop_duplicates()\n",
        "print(f\"âœ“ After removing duplicates: {len(combined_df)} rows\")\n",
        "\n",
        "# Display sample of combined data\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SAMPLE OF COMBINED DATA (first 10 rows):\")\n",
        "print(\"=\"*60)\n",
        "print(combined_df.head(10))\n",
        "\n",
        "# Display summary statistics\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUMMARY STATISTICS:\")\n",
        "print(\"=\"*60)\n",
        "if 'boat_count' in combined_df.columns:\n",
        "    print(f\"Total boat count: {combined_df['boat_count'].sum()}\")\n",
        "    print(f\"Average boat count: {combined_df['boat_count'].mean():.2f}\")\n",
        "    print(f\"Max boat count: {combined_df['boat_count'].max()}\")\n",
        "    print(f\"Min boat count: {combined_df['boat_count'].min()}\")\n",
        "\n",
        "# Save the combined data to a new CSV file\n",
        "output_filename = 'combined_boat_data.csv'\n",
        "combined_df.to_csv(output_filename, index=False)\n",
        "\n",
        "print(f\"\\nâœ… SUCCESS! Combined data saved to: {output_filename}\")\n",
        "print(\"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
